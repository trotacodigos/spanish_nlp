{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "670f94c7-2f68-40d8-8349-aefa4aea0c65",
   "metadata": {},
   "source": [
    "## Spanish NLP Libraries\n",
    "- tokenizer, customizing\n",
    "- noun extraction, POS, lemma\n",
    "- ngrams\n",
    "- stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82058dbe-2284-4b87-b400-2f1cd73b3858",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.lang.es.examples import sentences\n",
    "\n",
    "import nltk.data\n",
    "from nltk.tokenize import word_tokenize, WordPunctTokenizer\n",
    "nltk.download('punkt', quiet=True)\n",
    "\n",
    "import textacy\n",
    "from textacy.extract import ngrams, entities\n",
    "\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c5266d-36c8-4af9-9dcc-02724abff48d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Tokenize\n",
    "1. spacy (https://spacy.io/models/es)\n",
    "4. textacy (https://textacy.readthedocs.io/en/latest/quickstart.html#working-with-many-languages)\n",
    "2. NLTK spanish pickle, wordpunct\n",
    "3. Customary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0c3d9a-20bc-4759-879b-952d00666863",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 1. Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c4bf440-c5ba-4420-a5b5-058e27a38208",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Apple está buscando comprar una startup del Reino Unido por mil millones de dólares.',\n",
       " 'Los coches autónomos delegan la responsabilidad del seguro en sus fabricantes.',\n",
       " 'San Francisco analiza prohibir los robots delivery.',\n",
       " 'Londres es una gran ciudad del Reino Unido.',\n",
       " 'El gato come pescado.',\n",
       " 'Veo al hombre con el telescopio.',\n",
       " 'La araña come moscas.',\n",
       " 'El pingüino incuba en su nido sobre el hielo.',\n",
       " '¿Dónde estais?',\n",
       " '¿Quién es el presidente Francés?',\n",
       " '¿Dónde está encuentra la capital de Argentina?',\n",
       " '¿Cuándo nació José de San Martín?']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample text\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbe78edd-02cc-4019-8a65-e600fd3a7be9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Londres es una gran ciudad del Reino Unido.\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"es_core_news_sm\")\n",
    "doc = nlp(sentences[3]) # lower의 옵션도 고려할 수 있다.\n",
    "print(doc.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83836a68-3440-46b3-a40c-5fa2725dbd7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Londres, es, una, gran, ciudad, del, Reino, Unido, .]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenize\n",
    "spacy_tokens = [token for token in doc]\n",
    "sorted(spacy_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1191b686-d862-450c-b101-c3892ba08c90",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 2. Textacy\n",
    "- Since spaCy’s pipelines are language-dependent, we have to load a particular pipeline to match the text; when working with texts from multiple languages, this can be a pain. Fortunately, textacy includes automatic language detection to apply the right pipeline to the text, and it caches the loaded language data to minimize wait time and hassle. \n",
    "- 버전마다, 언어마다 되는 게 상이함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dbaccb75-4ee2-4cd6-8e94-252db9eed0f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Londres es una gran ciudad del Reino Unido."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttc_nlp = textacy.load_spacy_lang(\"es_core_news_sm\")\n",
    "ttc_doc = textacy.make_spacy_doc(sentences[3], lang=ttc_nlp)\n",
    "ttc_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19c0947c-71b8-4710-a2a9-f26135771ce9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Londres, es, una, gran, ciudad, del, Reino, Unido, .]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttc_tokens = [token for token in ttc_doc]\n",
    "sorted(ttc_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d753f8d-9207-4710-9ea7-d354183741c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Doc(9 tokens: \"Londres es una gran ciudad del Reino Unido.\")'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttc_doc._.preview # summary 역할"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09541fca-ff6b-4215-a328-0d4b9cbef997",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 3. NLTK\n",
    "- pickle: sentence splitter\n",
    "- WordPunct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34549229-2c4b-4400-b6ca-84ae7d43cb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk_tokenizer = nltk.data.load('tokenizers/punkt/spanish.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14bbded4-ad9c-4d15-bf0d-537f9af4c7a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Londres es una gran ciudad del Reino Unido.']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk_tokenizer.tokenize(sentences[3]) # 한 문장이므로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d97227c0-278f-42e7-8f57-1c91cbf6e810",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Apple está buscando comprar una startup del Reino Unido por mil millones de dólares.',\n",
       " 'Los coches autónomos delegan la responsabilidad del seguro en sus fabricantes.',\n",
       " 'San Francisco analiza prohibir los robots delivery.',\n",
       " 'Londres es una gran ciudad del Reino Unido.',\n",
       " 'El gato come pescado.',\n",
       " 'Veo al hombre con el telescopio.',\n",
       " 'La araña come moscas.',\n",
       " 'El pingüino incuba en su nido sobre el hielo.',\n",
       " '¿Dónde estais?',\n",
       " '¿Quién es el presidente Francés?',\n",
       " '¿Dónde está encuentra la capital de Argentina?',\n",
       " '¿Cuándo nació José de San Martín?']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk_tokenizer.tokenize(' '.join(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8d6aaa4-4bae-4353-9c3f-cee52334be31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['¿', 'Cuándo', 'nació', 'José', 'de', 'San', 'Martín', '?']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# wordpunct\n",
    "wp_tokenizer = WordPunctTokenizer()\n",
    "wp_tokenizer.tokenize(sentences[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1fc95572-8d27-4fb5-a5a1-c735c22d4246",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['¿Cuándo', 'nació', 'José', 'de', 'San', 'Martín', '?']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# word_tokenize와 비교 \n",
    "word_tokenize(sentences[-1]) # 영어에 없는 기호는 인식하지 못함."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0325b4b-08c5-4091-a181-2255fba7cbf9",
   "metadata": {},
   "source": [
    "#### 4. customizing\n",
    "내가 원하는 대로 토크나이저 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e5666250-fbab-401f-9f2d-b5edfa793334",
   "metadata": {},
   "outputs": [],
   "source": [
    "def treat_del(word:str):\n",
    "    ''' \n",
    "    del -> de, el\n",
    "    al -> a, el\n",
    "    '''\n",
    "    assert word.lower() in ['del', 'al'], 'wrong word'\n",
    "    word = word[:-1]\n",
    "    \n",
    "    return [word, 'el']\n",
    "    \n",
    "def a_tokenizer(sentence:str):\n",
    "    tokenizer = nltk.tokenize.WordPunctTokenizer()\n",
    "    tokens = tokenizer.tokenize(sentence.lower())\n",
    "    \n",
    "    for t in tokens:\n",
    "        if t in ['del', 'al']:\n",
    "            new =  treat_del(t)\n",
    "            tokens.extend(new)\n",
    "            tokens.remove(t)\n",
    "    return tokens\n",
    "\n",
    "def b_tokenizer(sentence:str):\n",
    "    nlp = spacy.load(\"es_core_news_sm\")\n",
    "    tokens = [str(token) for token in nlp(sentence.lower())]\n",
    "    \n",
    "    for t in tokens:\n",
    "        if t in ['del', 'al']:\n",
    "            new =  treat_del(t)\n",
    "            tokens.extend(new)\n",
    "            tokens.remove(t)\n",
    "    return tokens\n",
    "\n",
    "def ab_tokenizer(sentence:str, tokenizer=WordPunctTokenizer()):\n",
    "    # 토크나이저에 따른 토큰 방식\n",
    "    sentence = sentence.lower()\n",
    "    tokenizer_name = str(tokenizer).lower()\n",
    "    \n",
    "    if tokenizer_name == 'nlp':\n",
    "        nlp = spacy.load(\"es_core_news_sm\")\n",
    "        tokens = [str(token) for token in nlp(sentence)]\n",
    "    elif 'word_tokenize' in tokenizer_name.split():\n",
    "        tokens = tokenizer(sentence)\n",
    "    else:  # nltk의 다른 모든 토크나이저\n",
    "        tokens = tokenizer.tokenize(sentence)\n",
    "    \n",
    "    for t in tokens:\n",
    "        if t in ['del', 'al']:\n",
    "            new =  treat_del(t)\n",
    "            tokens.extend(new)\n",
    "            tokens.remove(t)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "85ea8f55-8f33-4638-a867-5e3d12a3c234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       apple               apple               apple        \n",
      "        está                está                está        \n",
      "      buscando            buscando            buscando      \n",
      "      comprar             comprar             comprar       \n",
      "        una                 una                 una         \n",
      "      startup             startup             startup       \n",
      "       reino               reino               reino        \n",
      "       unido               unido               unido        \n",
      "        por                 por                 por         \n",
      "        mil                 mil                 mil         \n",
      "      millones            millones            millones      \n",
      "         de                  de                  de         \n",
      "      dólares             dólares             dólares       \n",
      "         .                   .                   .          \n",
      "         de                  de                  de         \n",
      "         el                  el                  el         \n"
     ]
    }
   ],
   "source": [
    "for a, b, c in zip(a_tokenizer(sentences[0]),\n",
    "                   b_tokenizer(sentences[0]),\n",
    "                   ab_tokenizer(sentences[0], nltk.tokenize.word_tokenize)):\n",
    "    print('{0:^20}{1:^20}{2:^20}'.format(a, b, c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e71d3bf9-857d-49fc-9da3-3c42162fe5cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['apple',\n",
       " 'está',\n",
       " 'buscando',\n",
       " 'comprar',\n",
       " 'una',\n",
       " 'startup',\n",
       " 'reino',\n",
       " 'unido',\n",
       " 'por',\n",
       " 'mil',\n",
       " 'millones',\n",
       " 'de',\n",
       " 'dólares',\n",
       " '.',\n",
       " 'de',\n",
       " 'el']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_tokenizer(sentences[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ccd5d22-1d5a-4c2b-8cd9-f4e890d9665c",
   "metadata": {},
   "source": [
    "### noun extraction, POS, lemma\n",
    "- 명사 추출\n",
    "- POS (part-of-speeech)\n",
    "- lemma: 표제어"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa91192-0552-4fc0-b9ec-d87387556b70",
   "metadata": {},
   "source": [
    "#### spacy로 명사 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c1b4ca63-76c2-48ef-8428-8241fdfa763f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original=  los coches autónomos delegan la responsabilidad del seguro en sus fabricantes.\n",
      "nouns=  [los coches, la responsabilidad, seguro, sus fabricantes]\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(sentences[1].lower())\n",
    "test = list(doc.noun_chunks)\n",
    "print('original= ', doc)\n",
    "print('nouns= ', test) # 관사도 같이 추출됨을 알 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "29d39290-8775-486c-94a4-c82788b9e420",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('los', 'DET'),\n",
       " ('coches', 'NOUN'),\n",
       " ('autónomos', 'ADJ'),\n",
       " ('delegan', 'VERB'),\n",
       " ('la', 'DET'),\n",
       " ('responsabilidad', 'NOUN'),\n",
       " ('del', 'ADP'),\n",
       " ('seguro', 'NOUN'),\n",
       " ('en', 'ADP'),\n",
       " ('sus', 'DET'),\n",
       " ('fabricantes', 'NOUN'),\n",
       " ('.', 'PUNCT')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 전체 단어의 POS\n",
    "[(token.text, token.pos_) for token in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "06ad6748-1f12-467e-b07a-d2a6bcbafef3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('los', 'el'),\n",
       " ('coches', 'coche'),\n",
       " ('autónomos', 'autónomo'),\n",
       " ('delegan', 'delegar'),\n",
       " ('la', 'el'),\n",
       " ('responsabilidad', 'responsabilidad'),\n",
       " ('del', 'del'),\n",
       " ('seguro', 'seguro'),\n",
       " ('en', 'en'),\n",
       " ('sus', 'su'),\n",
       " ('fabricantes', 'fabricante'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 전체 단어의 표제어 추출\n",
    "[(token.text, token.lemma_) for token in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b531a5a4-c107-4cef-ab51-092c49717475",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(los coches, 'NOUN', 'coche'),\n",
       " (la responsabilidad, 'NOUN', 'responsabilidad'),\n",
       " (seguro, 'NOUN', 'seguro'),\n",
       " (sus fabricantes, 'NOUN', 'fabricante')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 추출된 명사의 (단어, POS, 레마)\n",
    "[(np, np.root.tag_, np.root.lemma_) for np in test] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed8f1b0-04fb-44e6-80d6-8d5a9ecff07a",
   "metadata": {},
   "source": [
    "#### textacy의 부가적 기능\n",
    "- textstats: compute various basic and readability statistics\n",
    "- text_utils.keyword_in_context: 해당 단어가 나타나는 문맥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "726926ed-14d5-48a1-a54e-29b79f450222",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Londres es una gran ciudad del Reino Unido."
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttc_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b90a8201-9e1a-41aa-bbc4-ca8147440428",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_stats = textacy.TextStats(ttc_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eaacae16-6b1b-44f5-aaa6-e5dc85a99759",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 11, 35)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (단어 수, 음절 수, 알파벳 수)\n",
    "text_stats.n_words, text_stats.n_syllables, text_stats.n_chars "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ce8ac2c4-61d4-4840-92fc-fe8f9a799e4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 엔트로피: 문장이 얼마나 많은 정보를 갖고 있는가\n",
    "text_stats.entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9e659115-a26c-454f-bed4-48b0f3ad6bcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3.7550000000000026, 116.17500000000001)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 가독성 (1-100)\n",
    "text_stats.flesch_kincaid_grade_level, text_stats.flesch_reading_ease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "616af0d3-18eb-4f20-8ac2-5737171670d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Londres es una  gran  ciudad del Reino Un\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 문맥 정보 (다량의 코퍼스에서 유용)\n",
    "list(textacy.text_utils.keyword_in_context(ttc_doc.text, 'gran', window_width=20)) # 주변 몇 글자를 볼 것인가"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3adb6f1a-0b5a-4880-b3f3-c5458ef5c6fd",
   "metadata": {},
   "source": [
    "### ngrams\n",
    "[Londres es], [es una], [una gran] ...\n",
    "- 앞뒤 n개의 단어 정보를 알려주는 기능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dbfec814-e361-45e9-9789-728d7a6dc500",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textacy.extract import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e62091c8-37d6-4ae4-baeb-a9c840cd1e95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Londres es,\n",
       " es una,\n",
       " una gran,\n",
       " gran ciudad,\n",
       " ciudad del,\n",
       " del Reino,\n",
       " Reino Unido,\n",
       " Unido.]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(ngrams(ttc_doc, 2,\n",
    "            filter_stops = False, # True=마지막만 출력\n",
    "           filter_punct = False, # True=문장부호 붙은 단어 제외\n",
    "           filter_nums = False,\n",
    "           min_freq = 1)) # 최소 빈도수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "188eecdc-be65-401f-886c-90def492be95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Londres es una,\n",
       " es una gran,\n",
       " una gran ciudad,\n",
       " gran ciudad del,\n",
       " ciudad del Reino,\n",
       " del Reino Unido]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 간단하게는\n",
    "list(ngrams(ttc_doc, 3, filter_stops=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32032e90-4bf5-4196-b6b4-bc0a32c1d487",
   "metadata": {},
   "source": [
    "### stopwords | 불용어\n",
    "자주 쓰이지만 중요한 의미를 내포하지 않으므로 주로 제거함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7327f886-fd28-421c-b850-0b32601a37ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7d127008-501b-4e5d-bb7b-f1c017b8d2fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['de', 'la', 'que', 'el', 'en', 'y', 'a', 'los', 'del', 'se', 'las', 'por', 'un', 'para', 'con', 'no', 'una', 'su', 'al', 'lo', 'como', 'más', 'pero', 'sus', 'le', 'ya', 'o', 'este', 'sí', 'porque', 'esta', 'entre', 'cuando', 'muy', 'sin', 'sobre', 'también', 'me', 'hasta', 'hay', 'donde', 'quien', 'desde', 'todo', 'nos', 'durante', 'todos', 'uno', 'les', 'ni', 'contra', 'otros', 'ese', 'eso', 'ante', 'ellos', 'e', 'esto', 'mí', 'antes', 'algunos', 'qué', 'unos', 'yo', 'otro', 'otras', 'otra', 'él', 'tanto', 'esa', 'estos', 'mucho', 'quienes', 'nada', 'muchos', 'cual', 'poco', 'ella', 'estar', 'estas', 'algunas', 'algo', 'nosotros', 'mi', 'mis', 'tú', 'te', 'ti', 'tu', 'tus', 'ellas', 'nosotras', 'vosotros', 'vosotras', 'os', 'mío', 'mía', 'míos', 'mías', 'tuyo', 'tuya', 'tuyos', 'tuyas', 'suyo', 'suya', 'suyos', 'suyas', 'nuestro', 'nuestra', 'nuestros', 'nuestras', 'vuestro', 'vuestra', 'vuestros', 'vuestras', 'esos', 'esas', 'estoy', 'estás', 'está', 'estamos', 'estáis', 'están', 'esté', 'estés', 'estemos', 'estéis', 'estén', 'estaré', 'estarás', 'estará', 'estaremos', 'estaréis', 'estarán', 'estaría', 'estarías', 'estaríamos', 'estaríais', 'estarían', 'estaba', 'estabas', 'estábamos', 'estabais', 'estaban', 'estuve', 'estuviste', 'estuvo', 'estuvimos', 'estuvisteis', 'estuvieron', 'estuviera', 'estuvieras', 'estuviéramos', 'estuvierais', 'estuvieran', 'estuviese', 'estuvieses', 'estuviésemos', 'estuvieseis', 'estuviesen', 'estando', 'estado', 'estada', 'estados', 'estadas', 'estad', 'he', 'has', 'ha', 'hemos', 'habéis', 'han', 'haya', 'hayas', 'hayamos', 'hayáis', 'hayan', 'habré', 'habrás', 'habrá', 'habremos', 'habréis', 'habrán', 'habría', 'habrías', 'habríamos', 'habríais', 'habrían', 'había', 'habías', 'habíamos', 'habíais', 'habían', 'hube', 'hubiste', 'hubo', 'hubimos', 'hubisteis', 'hubieron', 'hubiera', 'hubieras', 'hubiéramos', 'hubierais', 'hubieran', 'hubiese', 'hubieses', 'hubiésemos', 'hubieseis', 'hubiesen', 'habiendo', 'habido', 'habida', 'habidos', 'habidas', 'soy', 'eres', 'es', 'somos', 'sois', 'son', 'sea', 'seas', 'seamos', 'seáis', 'sean', 'seré', 'serás', 'será', 'seremos', 'seréis', 'serán', 'sería', 'serías', 'seríamos', 'seríais', 'serían', 'era', 'eras', 'éramos', 'erais', 'eran', 'fui', 'fuiste', 'fue', 'fuimos', 'fuisteis', 'fueron', 'fuera', 'fueras', 'fuéramos', 'fuerais', 'fueran', 'fuese', 'fueses', 'fuésemos', 'fueseis', 'fuesen', 'sintiendo', 'sentido', 'sentida', 'sentidos', 'sentidas', 'siente', 'sentid', 'tengo', 'tienes', 'tiene', 'tenemos', 'tenéis', 'tienen', 'tenga', 'tengas', 'tengamos', 'tengáis', 'tengan', 'tendré', 'tendrás', 'tendrá', 'tendremos', 'tendréis', 'tendrán', 'tendría', 'tendrías', 'tendríamos', 'tendríais', 'tendrían', 'tenía', 'tenías', 'teníamos', 'teníais', 'tenían', 'tuve', 'tuviste', 'tuvo', 'tuvimos', 'tuvisteis', 'tuvieron', 'tuviera', 'tuvieras', 'tuviéramos', 'tuvierais', 'tuvieran', 'tuviese', 'tuvieses', 'tuviésemos', 'tuvieseis', 'tuviesen', 'teniendo', 'tenido', 'tenida', 'tenidos', 'tenidas', 'tened']\n"
     ]
    }
   ],
   "source": [
    "stop_words = stopwords.words('spanish')\n",
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "420c4533-75d1-40b7-a520-2b5f8ccc709a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "313"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "429b2e74-f1d4-4c78-a37e-36a15b8bddad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Apple está buscando comprar una startup del Reino Unido por mil millones de dólares.'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7174d44f-a043-4a81-a7da-ba50a9472dca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Apple',\n",
       " 'buscando',\n",
       " 'comprar',\n",
       " 'startup',\n",
       " 'Reino',\n",
       " 'Unido',\n",
       " 'mil',\n",
       " 'millones',\n",
       " 'dólares',\n",
       " '.']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenize -> stopwords 제거\n",
    "[w for w in word_tokenize(sentences[0]) if w.lower() not in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2a37eac2-01bc-4275-a1c7-0b9957671be7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Apple buscando comprar startup Reino Unido mil millones dólares .'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(w for w in word_tokenize(sentences[0]) if w.lower() not in stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ddd8f1-0dc7-48b7-820b-696b30b7c735",
   "metadata": {},
   "source": [
    "### Summary\n",
    "작업의 목표:\n",
    "- 코퍼스에 대한 이해\n",
    "- 원하는 테스크에 맞는 단어 선별 (중요한 단어만 남기기 위함)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483ab803-9b3f-41e1-8b65-1d210cd163d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
