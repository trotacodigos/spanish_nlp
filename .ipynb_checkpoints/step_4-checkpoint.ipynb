{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8df667e3-72b3-4ad2-89c2-d0cf157cfb9f",
   "metadata": {},
   "source": [
    "## 감정분석 + BERT\n",
    "버트로 모델링하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb2b296-2789-4afc-9785-4b4c68e9cffa",
   "metadata": {
    "tags": []
   },
   "source": [
    "### BERT - airline review sentiment analysis\n",
    "- 목표: 만든 파일로 모델을 만들어서 모델이 리뷰를 positive, negative로 잘 분류할 수 있게 한다.\n",
    "1. train, test set으로 나눔\n",
    "2. train set으로 모델을 만들고\n",
    "3. test set에서 정확도를 계산한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "337212c8-756e-400f-9260-317ef00fd06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import tensorflow as tf\n",
    "from transformers import BertTokenizer, TFBertModel\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9baa0f15-0ab9-4842-b62b-b0e617a251f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random seed 고정\n",
    "tf.random.set_seed(1234)\n",
    "np.random.seed(123)\n",
    "\n",
    "# parameters\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 3\n",
    "VALID_SPLIT = 0.2\n",
    "MAX_LEN = 16 * 2\n",
    "\n",
    "OUT_PATH = '../data_out/'\n",
    "IN_PATH = '../data'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf299a86-1d26-4822-a6e0-febde7df976a",
   "metadata": {},
   "source": [
    "#### load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8fac9399-c5a5-48c3-8cb4-bc731d94a038",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>at</th>\n",
       "      <th>polarity</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Trabajar en Ryanair como TMA:  empleo</td>\n",
       "      <td>neutral</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.230391</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Cuando gusten en Cancún se viaja y disfruta ...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>@Iberia</td>\n",
       "      <td>0.025044</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Sabiais que  te trata muy bien en santiago de ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.350941</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unnamed: 0                                               text  \\\n",
       "0          0              Trabajar en Ryanair como TMA:  empleo   \n",
       "1          1    Cuando gusten en Cancún se viaja y disfruta ...   \n",
       "2          2  Sabiais que  te trata muy bien en santiago de ...   \n",
       "\n",
       "  airline_sentiment       at  polarity  label  \n",
       "0           neutral      NaN  0.230391    0.0  \n",
       "1           neutral  @Iberia  0.025044    0.0  \n",
       "2          negative      NaN  0.350941    2.0  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = os.path.join(IN_PATH, 'OUT', 'tweets_public_polarity.csv')\n",
    "\n",
    "df = pd.read_csv(file, sep='\\t', encoding='utf-8')\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "96de1399-59e8-4ff1-bbd0-fad65faa1327",
   "metadata": {},
   "outputs": [],
   "source": [
    "del df['Unnamed: 0']\n",
    "df = df.dropna() # 없는 값 삭제하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6595acd-05ac-4a9b-9c5a-5a6818b79078",
   "metadata": {},
   "source": [
    "#### max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0514ce41-f271-488b-8409-85c6a3c7c92e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hello', ',', 'world', '.']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MAX_LEN는 average * 2\n",
    "import nltk\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "tokenizer = WordPunctTokenizer()\n",
    "\n",
    "# test\n",
    "tokenizer.tokenize('hello, world.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "511a5932-8c3c-4cfc-b889-232397e9a223",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>at</th>\n",
       "      <th>polarity</th>\n",
       "      <th>label</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cuando gusten en Cancún se viaja y disfruta ...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>@Iberia</td>\n",
       "      <td>0.025044</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text airline_sentiment  \\\n",
       "1    Cuando gusten en Cancún se viaja y disfruta ...           neutral   \n",
       "\n",
       "        at  polarity  label  tokens  \n",
       "1  @Iberia  0.025044    0.0      12  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tokens'] = df.text.apply(lambda x: len(tokenizer.tokenize(str(x))))\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "252f70c9-276a-4d8c-a034-a0fbc7513cb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    3695.000000\n",
       "mean       15.928552\n",
       "std         7.425084\n",
       "min         0.000000\n",
       "25%        10.000000\n",
       "50%        18.000000\n",
       "75%        22.000000\n",
       "max        34.000000\n",
       "Name: tokens, dtype: float64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tokens.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc45eaef-24cb-4aa9-856f-48063db323af",
   "metadata": {
    "tags": []
   },
   "source": [
    "### train, test set 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "88c08998-dfd2-4a62-b748-9a4833e73bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = train_test_split(df, test_size=0.2, shuffle=True, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a0a105d5-ae35-47c2-9fd7-1c8175e271df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2956, 739)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train), len(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00150706-e92b-4a81-9948-64dee407e1d7",
   "metadata": {},
   "source": [
    "#### df label 개수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "383e70e8-fb98-4d26-a065-79111207a936",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0    1627\n",
       "0.0     885\n",
       "1.0     444\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "16a20bfa-d7e5-4e64-b78b-73bc67e185cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>at</th>\n",
       "      <th>polarity</th>\n",
       "      <th>label</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2436</th>\n",
       "      <td>Pues si y no. Pq me dijeron que probablemente...</td>\n",
       "      <td>negative</td>\n",
       "      <td>@Iberia</td>\n",
       "      <td>1.610742e-10</td>\n",
       "      <td>2.0</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>L…</td>\n",
       "      <td>negative</td>\n",
       "      <td>@planeaconlena</td>\n",
       "      <td>4.978923e-01</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2622</th>\n",
       "      <td>Bueno Ryanair es low cost...</td>\n",
       "      <td>negative</td>\n",
       "      <td>@QuiqueBoeing</td>\n",
       "      <td>5.804897e-01</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7408</th>\n",
       "      <td>Habeis escrito algo después de lo q yo os he ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>@Iberia</td>\n",
       "      <td>8.509542e-06</td>\n",
       "      <td>2.0</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text airline_sentiment  \\\n",
       "2436   Pues si y no. Pq me dijeron que probablemente...          negative   \n",
       "489                                                 L…           negative   \n",
       "2622                       Bueno Ryanair es low cost...          negative   \n",
       "7408   Habeis escrito algo después de lo q yo os he ...          negative   \n",
       "\n",
       "                  at      polarity  label  tokens  \n",
       "2436         @Iberia  1.610742e-10    2.0      23  \n",
       "489   @planeaconlena  4.978923e-01    2.0       2  \n",
       "2622   @QuiqueBoeing  5.804897e-01    2.0       6  \n",
       "7408         @Iberia  8.509542e-06    2.0      23  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.sample(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46b6273-6ee3-467a-ac20-e46dc426e910",
   "metadata": {},
   "source": [
    "### BERT tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "878a8411-f276-410d-8fc6-59a20dac63ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased', \n",
    "                                          cache_dir='bert_ckpt',\n",
    "                                          do_lower_case=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0e7701e6-4cb6-414d-a091-8d8f7e8d35b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101, 110516, 10113, 117, 10110, 62745, 11153, 106, 102]\n",
      "['[ C L S ]', 'h o l', '# # a', ',', 'e n', '# # c a n t', '# # a d a', '!', '[ S E P ]']\n"
     ]
    }
   ],
   "source": [
    "sent = 'hola, encantada!'\n",
    "encode = tokenizer.encode(sent)\n",
    "token_print = [tokenizer.decode(token) for token in encode]\n",
    "\n",
    "print(encode)\n",
    "print(token_print)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b6feca2b-5423-4493-8a4c-1c51bbcd9f05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[UNK]', '[SEP]', '[PAD]', '[CLS]', '[MASK]'] \n",
      " [100, 102, 0, 101, 103]\n"
     ]
    }
   ],
   "source": [
    "# 버트에 있는 토큰 종류들\n",
    "print(tokenizer.all_special_tokens, '\\n', tokenizer.all_special_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "32ac7b2d-beb0-4766-a01d-f10a36eb0b1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2956 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2217: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "100%|██████████| 2956/2956 [00:00<00:00, 3145.05it/s]\n"
     ]
    }
   ],
   "source": [
    "def bert_tokenizer(sent, MAX_LEN):\n",
    "    \n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "        text=sent,\n",
    "        add_special_tokens=True,\n",
    "        max_length=MAX_LEN,\n",
    "        pad_to_max_length=True,\n",
    "        return_attention_mask=True\n",
    "    )\n",
    "    \n",
    "    input_id = encoded_dict['input_ids']\n",
    "    attention_mask = encoded_dict['attention_mask']\n",
    "    token_type_id = encoded_dict['token_type_ids']\n",
    "    \n",
    "    return input_id, attention_mask, token_type_id\n",
    "\n",
    "input_ids = []\n",
    "attention_masks = []\n",
    "token_type_ids = []\n",
    "train_data_labels = []\n",
    "\n",
    "for train_sent, train_label in tqdm(zip(X_train.text, X_train.label), total=len(X_train)):\n",
    "    try:\n",
    "        input_id, attention_mask, token_type_id = bert_tokenizer(train_sent, MAX_LEN)\n",
    "        \n",
    "        input_ids.append(input_id)\n",
    "        attention_masks.append(attention_mask)\n",
    "        token_type_ids.append(token_type_id)\n",
    "        train_data_labels.append(train_label)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(train_sent)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ef20d3e2-da55-4cf2-853c-132f38f0376f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_ids = np.array(input_ids, dtype=int)\n",
    "train_attention_masks = np.array(attention_masks, dtype=int)\n",
    "train_type_ids = np.array(token_type_ids, dtype=int)\n",
    "train_inputs = (train_input_ids, train_attention_masks, train_type_ids)\n",
    "\n",
    "train_data_labels = np.asarray(train_data_labels, dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "df109f0a-216a-44ed-a22b-21d4c3a57135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# sent: 2956, # labels: 2956\n"
     ]
    }
   ],
   "source": [
    "print('# sent: {}, # labels: {}'.format(len(train_input_ids), len(train_data_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1388bacb-985a-4e03-83d1-ed2aea5fdc35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   101  10657  12796 107788  16466  20039  11559  18345  10121 100154\n",
      "  55174    102      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[CLS] No worries Ryanair está mejor que Vueling [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n"
     ]
    }
   ],
   "source": [
    "input_id = train_input_ids[1]\n",
    "attention_mask = train_attention_masks[1]\n",
    "token_type_id = train_type_ids[1]\n",
    "\n",
    "print(input_id)\n",
    "print(attention_mask)\n",
    "print(token_type_id)\n",
    "print(tokenizer.decode(input_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa1b4f7-be15-45f3-be6b-df770f446186",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f10bcd92-3662-4e17-b48c-e6d14fb8867d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dade2f16d7148bdbe437a7884fbde67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/625 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f36905aeed024681bfc2c056fc73f3c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.01G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-base-multilingual-cased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-multilingual-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "class TFBertClassifier(tf.keras.Model):\n",
    "    def __init__(self, model_name, dir_path, num_class):\n",
    "        super(TFBertClassifier, self).__init__()\n",
    "        \n",
    "        self.bert = TFBertModel.from_pretrained(model_name, cache_dir=dir_path)\n",
    "        self.dropout = tf.keras.layers.Dropout(self.bert.config.hidden_dropout_prob)\n",
    "        self.classifier = tf.keras.layers.Dense(num_class,\n",
    "                                               kernel_initializer=tf.keras.initializers.TruncatedNormal(self.bert.config.initializer_range),\n",
    "                                               name='classifier')\n",
    "        \n",
    "    def call(self, inputs, attention_mask=None, token_type_ids=None, training=False):\n",
    "        outputs = self.bert(inputs, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "        pooled_output = outputs[1]\n",
    "        pooled_output = self.dropout(pooled_output, training=training)\n",
    "        logits = self.classifier(pooled_output)\n",
    "        \n",
    "        return logits\n",
    "    \n",
    "cls_model = TFBertClassifier(model_name='bert-base-multilingual-cased',\n",
    "                            dir_path='bert_ckpt',\n",
    "                            num_class=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621bf05b-1cfb-4bd0-a48a-fe7c15c6965e",
   "metadata": {},
   "source": [
    "#### optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4e95d162-6e93-4d8b-a429-af6601a637f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(3e-5)\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
    "cls_model.compile(optimizer=optimizer,\n",
    "                 loss=loss,\n",
    "                 metrics=[metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "114c64dc-db9b-42a7-9113-43a08b776d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'tf2_bert_es_airline_sentiment'\n",
    "\n",
    "earlystop_callback = EarlyStopping(monitor='val_accuracy', min_delta=0.0001, patience=2)\n",
    "checkpoint_path = os.path.join(OUT_PATH, model_name, 'weights.h5')\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "if os.path.exists(checkpoint_dir):\n",
    "    print(\"{} -- Folder already exists \\n\".format(checkpoint_dir))\n",
    "else:\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    \"{} -- Folder create complete \\n\".format(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "44f0333e-42d2-41bd-a340-b723870bb941",
   "metadata": {},
   "outputs": [],
   "source": [
    "cp_callback = ModelCheckpoint(\n",
    "    checkpoint_path, monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "71077e55-c80e-43a6-9ee5-6a240cd1d551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_ops.py:5049: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n",
      "74/74 [==============================] - 19s 82ms/step - loss: nan - accuracy: 0.2936 - val_loss: nan - val_accuracy: 0.3209\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.32095, saving model to ../data_out/tf2_bert_es_airline_sentiment/weights.h5\n",
      "Epoch 2/3\n",
      "74/74 [==============================] - 4s 55ms/step - loss: nan - accuracy: 0.2940 - val_loss: nan - val_accuracy: 0.3209\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.32095\n",
      "Epoch 3/3\n",
      "74/74 [==============================] - 4s 57ms/step - loss: nan - accuracy: 0.2940 - val_loss: nan - val_accuracy: 0.3209\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.32095\n",
      "{'loss': [nan, nan, nan], 'accuracy': [0.29357022047042847, 0.2939932346343994, 0.2939932346343994], 'val_loss': [nan, nan, nan], 'val_accuracy': [0.32094594836235046, 0.32094594836235046, 0.32094594836235046]}\n"
     ]
    }
   ],
   "source": [
    "history = cls_model.fit(train_inputs, train_data_labels,\n",
    "                        epochs=NUM_EPOCHS,\n",
    "                        batch_size=BATCH_SIZE,\n",
    "                       validation_split=VALID_SPLIT,\n",
    "                       callbacks=[earlystop_callback, cp_callback])\n",
    "\n",
    "print(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "83e55a5a-493b-451b-835f-65da7c1552f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_graphs(history, string):\n",
    "    plt.plot(history.history[string])\n",
    "    plt.plot(history.history['val_'+string], '')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel(string)\n",
    "    plt.legend([string, 'val_'+string])\n",
    "    plt.show()\n",
    "    \n",
    "plot_graphs(history, 'loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93eff841-6e61-4f81-ad4b-9ed6314c5a7c",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d36f8568-bbac-4f2f-98d5-d38273efac75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>at</th>\n",
       "      <th>polarity</th>\n",
       "      <th>label</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3547</th>\n",
       "      <td>sí  ya he volado pero no tengo la tarjeta de ...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>@Iberia</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text airline_sentiment  \\\n",
       "3547   sí  ya he volado pero no tengo la tarjeta de ...           neutral   \n",
       "\n",
       "           at  polarity  label  tokens  \n",
       "3547  @Iberia  0.000048    0.0      11  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "81d1555e-18f8-471c-bc3b-aebc2cb2afa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2217: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "739it [00:00, 3389.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num sents, labels 739, 739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "input_ids = []\n",
    "attention_masks = []\n",
    "token_type_ids = []\n",
    "test_data_labels = []\n",
    "\n",
    "for test_sent, test_label in tqdm(zip(X_test.text, X_test.label)):\n",
    "    try:\n",
    "        input_id, attention_mask, token_type_id = bert_tokenizer(test_sent, MAX_LEN)\n",
    "        \n",
    "        input_ids.append(input_id)\n",
    "        attention_masks.append(attention_mask)\n",
    "        token_type_ids.append(token_type_id)\n",
    "        test_data_labels.append(test_label)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(test_sent)\n",
    "        pass\n",
    "    \n",
    "test_input_ids = np.array(input_ids, dtype=int)\n",
    "test_attention_masks = np.array(attention_masks, dtype=int)\n",
    "test_type_ids = np.array(token_type_ids, dtype=int)\n",
    "test_inputs = (test_input_ids, test_attention_masks, test_type_ids)\n",
    "test_data_labels = np.asarray(test_data_labels, dtype=np.int32)\n",
    "\n",
    "print(\"num sents, labels {}, {}\".format(len(test_input_ids), len(test_data_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "02406aa4-322e-4d83-9241-4d740a1a76d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 200ms/step - loss: nan - accuracy: 0.3180\n",
      "test loss, test acc:  [nan, 0.3179973065853119]\n"
     ]
    }
   ],
   "source": [
    "results = cls_model.evaluate(test_inputs, test_data_labels, batch_size=1024)\n",
    "print('test loss, test acc: ', results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "94795350-2d4e-4d33-a79c-b4490129ad8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7110</th>\n",
       "      <td>Este avion tiene 12 años de antiguedad y entr...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506</th>\n",
       "      <td>Envié un privado x una reserva, podrán soluc...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6869</th>\n",
       "      <td>Si Ryanair cobra por esto y al final el total...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4407</th>\n",
       "      <td>Por suerte viaja mi amigo...yo estoy disf...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6384</th>\n",
       "      <td>Es una pena que sea una práctica comercial l...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label\n",
       "7110   Este avion tiene 12 años de antiguedad y entr...    0.0\n",
       "506     Envié un privado x una reserva, podrán soluc...    2.0\n",
       "6869   Si Ryanair cobra por esto y al final el total...    0.0\n",
       "4407       Por suerte viaja mi amigo...yo estoy disf...    1.0\n",
       "6384    Es una pena que sea una práctica comercial l...    2.0"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.loc[:, ['text', 'label']].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3430c02-14f7-4fe3-8e6b-d81148382440",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict = {'negative': 2, 'positive': 1, 'neutral': 0}\n",
    "\n",
    "def find_label(num_label):\n",
    "    return next(key for key, value in label_dict.items() if value == num_label) # 반복할 수 있을 때는 해당 값을 출력하고, 반복이 끝났을 때는 기본값을 출력"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
